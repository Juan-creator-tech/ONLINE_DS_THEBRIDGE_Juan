{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "110d0bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'depth': 7, 'iterations': 200, 'learning_rate': 0.1}\n",
      "Mejor MSE en CV: 285898538500.78534\n",
      "\n",
      "Evaluación en test:\n",
      "MSE:  246904840418.552\n",
      "MAE:  235352.851\n",
      "R²:   0.842\n",
      "\n",
      "Modelo guardado en 'best_catboost_model.pkl'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# ----------------------------------------\n",
    "# Wrapper de CatBoost que detecta automáticamente\n",
    "# las columnas categóricas (tipo object) y las pasa a fit.\n",
    "class CatBoostWrapper(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, iterations=100, learning_rate=0.1, depth=6, **kwargs):\n",
    "        self.iterations = iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        self.depth = depth\n",
    "        self.kwargs = kwargs\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Detecta índices de columnas categóricas (dtype object)\n",
    "        cat_features = np.where(X.dtypes == 'object')[0].tolist()\n",
    "        # Asegurarse de que no hay floats en columnas categóricas\n",
    "        X = X.copy()\n",
    "        for col_idx in cat_features:\n",
    "            col_name = X.columns[col_idx]\n",
    "            X[col_name] = X[col_name].astype(str)\n",
    "\n",
    "        self.model = CatBoostRegressor(\n",
    "            iterations=self.iterations,\n",
    "            learning_rate=self.learning_rate,\n",
    "            depth=self.depth,\n",
    "            verbose=0,\n",
    "            **self.kwargs\n",
    "        )\n",
    "        self.model.fit(X, y, cat_features=cat_features)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "# ----------------------------------------\n",
    "# Función para cargar el dataset desde un archivo CSV\n",
    "def load_data(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    return df\n",
    "\n",
    "# ----------------------------------------\n",
    "# Función de preprocesamiento mínimo\n",
    "def preprocess_data(df):\n",
    "    # Se eliminan columnas descartables\n",
    "    cols_to_drop = ['provincia', 'PrecioAnterior', 'Enlace', 'ascensor', 'localizacion', 'planta', 'tags', 'descripcion']\n",
    "    df = df.drop(columns=cols_to_drop, errors='ignore')\n",
    "    \n",
    "    df['TipoVivienda'] = df['titulo'].str.strip().str.split().str[0]\n",
    "    df = df.drop(columns='titulo')\n",
    "    # En este ejemplo se dejan las demás columnas tal cual,\n",
    "    # por lo que las variables categóricas se mantienen en su forma original.\n",
    "    # Puedes, si lo consideras, hacer otros ajustes mínimos.\n",
    "    df = df.rename(columns={\"baños\": \"banos\"})\n",
    "    # Eliminar filas con valores nulos (opcional, según la situación)\n",
    "    df = df.fillna(\"N/A\")\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "# ----------------------------------------\n",
    "# Función para separar la variable objetivo y las features\n",
    "def separate_target(df):\n",
    "    y = df['PrecioActual']\n",
    "    X = df.drop(columns=['PrecioActual'])\n",
    "    cat_features = np.where(X.dtypes == 'object')[0].tolist()\n",
    "    X = X.copy()\n",
    "    for col_idx in cat_features:\n",
    "        col_name = X.columns[col_idx]\n",
    "        X[col_name] = X[col_name].astype(str)\n",
    "    return X, y\n",
    "\n",
    "# ----------------------------------------\n",
    "# Función para optimizar hiperparámetros usando GridSearchCV\n",
    "def tune_model(estimator, param_grid, X_train, y_train):\n",
    "    grid = GridSearchCV(estimator, param_grid=param_grid, \n",
    "                        cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_estimator = grid.best_estimator_\n",
    "    best_cv_mse = -grid.best_score_\n",
    "    print(\"Mejores parámetros:\", grid.best_params_)\n",
    "    print(\"Mejor MSE en CV:\", best_cv_mse)\n",
    "    return best_estimator, best_cv_mse\n",
    "\n",
    "# ----------------------------------------\n",
    "# Función para evaluar el modelo en el conjunto de test\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return mse, mae, r2\n",
    "\n",
    "# ----------------------------------------\n",
    "# Función principal\n",
    "def main():\n",
    "    # 1. Cargar datos\n",
    "    filepath = './Datos.csv'  # Asegúrate de ajustar la ruta\n",
    "    df = load_data(filepath)\n",
    "    \n",
    "    # 2. Preprocesamiento (mínimo, sin transformar variables categóricas)\n",
    "    df = preprocess_data(df)\n",
    "    df.to_csv('Datos_preprocesados.csv', index=False)\n",
    "    # 3. Separar variable objetivo (PrecioActual) y variables predictoras\n",
    "    X, y = separate_target(df)\n",
    "    \n",
    "    # 4. División en conjuntos de entrenamiento y test (80% - 20%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 5. Definir el modelo (solo CatBoost) con el wrapper\n",
    "    catboost_model = CatBoostWrapper(random_state=42)\n",
    "    \n",
    "    # 6. Definir grid de hiperparámetros para CatBoost\n",
    "    param_grid = {\n",
    "        'iterations': [200],\n",
    "        'learning_rate': [0.1],\n",
    "        'depth': [7]\n",
    "    }\n",
    "    \n",
    "    # 7. Optimización con GridSearchCV\n",
    "    best_model, cv_mse = tune_model(catboost_model, param_grid, X_train, y_train)\n",
    "    \n",
    "    # 8. Evaluación en el conjunto de test\n",
    "    test_mse, test_mae, test_r2 = evaluate_model(best_model, X_test, y_test)\n",
    "    print(\"\\nEvaluación en test:\")\n",
    "    print(f\"MSE:  {test_mse:.3f}\")\n",
    "    print(f\"MAE:  {test_mae:.3f}\")\n",
    "    print(f\"R²:   {test_r2:.3f}\")\n",
    "    \n",
    "    # 8. Guardar el modelo optimizado en un archivo pickle\n",
    "    with open('best_catboost_model.pkl', 'wb') as f:\n",
    "        pickle.dump(best_model, f)\n",
    "    print(\"\\nModelo guardado en 'best_catboost_model.pkl'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a10fc532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11826 entries, 0 to 11825\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   provincia       11826 non-null  object \n",
      " 1   zona            11826 non-null  object \n",
      " 2   titulo          11826 non-null  object \n",
      " 3   PrecioActual    11826 non-null  int64  \n",
      " 4   PrecioAnterior  11826 non-null  int64  \n",
      " 5   metros          11826 non-null  int64  \n",
      " 6   habitaciones    11460 non-null  float64\n",
      " 7   ascensor        11033 non-null  object \n",
      " 8   localizacion    10730 non-null  object \n",
      " 9   planta          10601 non-null  object \n",
      " 10  baños           11826 non-null  int64  \n",
      " 11  tags            11664 non-null  object \n",
      " 12  descripcion     11761 non-null  object \n",
      " 13  Enlace          11826 non-null  object \n",
      "dtypes: float64(1), int64(4), object(9)\n",
      "memory usage: 1.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TipoVivienda\n",
       "Piso       9551\n",
       "Ático       782\n",
       "Dúplex      435\n",
       "Chalet      398\n",
       "Estudio     339\n",
       "Casa        321\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = './Datos.csv'\n",
    "df = pd.read_csv(filepath)\n",
    "df.info()\n",
    "cols_to_drop = ['provincia', 'PrecioAnterior', 'Enlace', 'ascensor', 'localizacion', 'planta', 'tags', 'descripcion']\n",
    "df = df.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "df['TipoVivienda'] = df['titulo'].str.strip().str.split().str[0]\n",
    "df = df.drop(columns='titulo')\n",
    "\n",
    "# En este ejemplo se dejan las demás columnas tal cual,\n",
    "# por lo que las variables categóricas se mantienen en su forma original.\n",
    "# Puedes, si lo consideras, hacer otros ajustes mínimos.\n",
    "\n",
    "# Eliminar filas con valores nulos (opcional, según la situación)\n",
    "df = df.fillna(\"N/A\")\n",
    "df = df.dropna()\n",
    "df\n",
    "df['TipoVivienda'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
