{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PowerTransformer\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Cargar los datos de train y test (asegúrate de tener los archivos o adaptar el código)\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Suponiendo que 'price_in_euros' es la variable objetivo\n",
    "X = train.drop(\"price_in_euros\", axis=1)\n",
    "y = train[\"price_in_euros\"]\n",
    "\n",
    "# Dividir el set de train en entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Identificar columnas numéricas y categóricas\n",
    "num_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "# Pipeline para variables numéricas: imputación, transformación para normalizar y escalado\n",
    "numeric_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"pt\", PowerTransformer(method=\"yeo-johnson\")),  # Ayuda a normalizar la distribución\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline para variables categóricas: imputación y codificación one-hot\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# Combinar ambos pipelines en un preprocesador\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num\", numeric_pipeline, num_cols),\n",
    "    (\"cat\", categorical_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "# Definir el modelo: XGBoost Regressor\n",
    "xgb_reg = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n",
    "\n",
    "# Crear el pipeline completo: preprocesado + modelo\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", xgb_reg)\n",
    "])\n",
    "\n",
    "# Definir el espacio de hiperparámetros a explorar\n",
    "param_grid = {\n",
    "    \"regressor__n_estimators\": [100, 300, 500],\n",
    "    \"regressor__max_depth\": [3, 5, 7],\n",
    "    \"regressor__learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"regressor__subsample\": [0.7, 0.8, 1.0],\n",
    "    \"regressor__colsample_bytree\": [0.7, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Definir el scorer usando RMSE (se utiliza un lambda para calcular la raíz del MSE)\n",
    "rmse_scorer = make_scorer(lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred)), greater_is_better=False)\n",
    "\n",
    "# Configurar la validación cruzada\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Búsqueda aleatoria de hiperparámetros\n",
    "random_search = RandomizedSearchCV(pipeline, param_distributions=param_grid, n_iter=30,\n",
    "                                   scoring=rmse_scorer, cv=cv, verbose=1,\n",
    "                                   random_state=42, n_jobs=-1)\n",
    "\n",
    "# Ajustar el modelo con el set de entrenamiento\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Mostrar los mejores hiperparámetros y el score obtenido\n",
    "print(\"Mejores hiperparámetros:\", random_search.best_params_)\n",
    "print(\"Mejor RMSE (score negativo):\", random_search.best_score_)\n",
    "\n",
    "# Evaluar el desempeño en el set de validación\n",
    "y_pred_val = random_search.predict(X_val)\n",
    "rmse_val = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "print(\"RMSE en validación:\", rmse_val)\n",
    "\n",
    "# Realizar predicciones sobre el set de test\n",
    "predictions_test = random_search.predict(test)\n",
    "\n",
    "# Guardar las predicciones (asumiendo que el test tiene una columna 'id' o se generan índices)\n",
    "output = pd.DataFrame({\n",
    "    \"id\": test[\"id\"] if \"id\" in test.columns else np.arange(len(test)),\n",
    "    \"price_in_euros\": predictions_test\n",
    "})\n",
    "output.to_csv(\"submission.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
